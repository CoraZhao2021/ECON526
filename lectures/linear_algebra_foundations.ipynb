{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ECON526: Quantitative Economics with Data Science Applications\n",
        "\n",
        "Foundations of Numerical Linear Algebra\n",
        "\n",
        "Jesse Perla\n",
        "\n",
        "## Motivation and Materials\n",
        "\n",
        "-   Data science, econometrics, and macroeconomics are built on linear\n",
        "    algebra.\n",
        "\n",
        "-   Numerical linear algebra has all sorts of pitfalls, which become\n",
        "    more critical as we scale up to larger problems.\n",
        "\n",
        "-   Speed differences in choosing better algorithms can be orders of\n",
        "    magnitude.\n",
        "\n",
        "-   Crucial to know what goes on under-the-hood in Stata/R/python\n",
        "    packages for applied work, even if you don’t implement it yourself.\n",
        "\n",
        "-   Material here is related to\n",
        "\n",
        "    -   [QuantEcon\n",
        "        Python](https://python.quantecon.org/linear_algebra.html)\n",
        "    -   [QuantEcon Data\n",
        "        Science](https://datascience.quantecon.org/scientific/applied_linalg.html)\n",
        "    -   [A First Course in Quantitative Economics with\n",
        "        Python](https://intro.quantecon.org/)\n",
        "\n",
        "## Packages\n",
        "\n",
        "This section uses the following packages:"
      ],
      "id": "82408f95-7c46-4edd-8f2c-bc628aa6389d"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from numpy.linalg import cond, matrix_rank, norm\n",
        "from scipy.linalg import inv, solve, det, eig, lu, eigvals\n",
        "from scipy.linalg import solve_triangular, eigvalsh, cholesky"
      ],
      "id": "9f233ca0-f305-4472-ac0c-46d0724ecc97"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Computational Complexity\n",
        "\n",
        "<span class=\"theorem-title\">**Definition 1 (Big-O Notation) **</span>For\n",
        "a function $f(N)$ and a positive constant $C$, we say $f(N)$ is\n",
        "$O(g(N))$, if there exist positive constants $C$ and $N_0$ such that:\n",
        "\n",
        "$$\n",
        "0 \\leq f(N) \\leq C \\cdot g(N) \\quad \\text{for all } N \\geq N_0\n",
        "$$\n",
        "\n",
        "-   Often crucial to know how problems scale asymptotically (as\n",
        "    $N\\to\\infty$)\n",
        "-   Caution: $f_1(N) = N^3 + N$ is $O(N^3)$ and\n",
        "    $f_2(N) = 1000 N^2 + 3 N$ is $O(N^2)$\n",
        "    -   Asymptotically choose $f_2(N)$ algorithm, but choose $f_1(N)$\n",
        "        for small $N$\n",
        "-   Simple examples:\n",
        "    -   $x \\cdot y = \\sum_{n=1}^N x_n y_n$ is $O(N)$ since it requires\n",
        "        $N$ multiplications and additions\n",
        "    -   $A x$ for $A\\in\\mathbb{R}^{N\\times N},x\\in\\mathbb{R}^N$ is\n",
        "        $O(N^2)$ since it requires $N$ dot products, each $O(N)$\n",
        "\n",
        "## Numerical Precision\n",
        "\n",
        "Computers have finite precision. 64-bit typical, but 32-bit on GPUs\n",
        "\n",
        "<span class=\"theorem-title\">**Definition 2 (Machine Epsilon)\n",
        "**</span>For a given datatype, $\\epsilon$ is defined as\n",
        "$\\epsilon = \\min_{\\delta > 0} \\left\\{ \\delta : 1 + \\delta > 1 \\right\\}$"
      ],
      "id": "7e60507a-9fad-44ff-93ef-4e2604d71651"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "machine epsilon for float64 = 2.220446049250313e-16\n",
            "1 + eps/2 == 1? True\n",
            "machine epsilon for float32 = 1.1920928955078125e-07"
          ]
        }
      ],
      "source": [
        "print(f\"machine epsilon for float64 = {np.finfo(float).eps}\")\n",
        "print(f\"1 + eps/2 == 1? {1.0 + 1.1e-16 == 1.0}\")\n",
        "print(f\"machine epsilon for float32 = {np.finfo(np.float32).eps}\")"
      ],
      "id": "2f76e7bb-8d4c-4829-b4de-e21cc0f0f292"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic Linear Algebra\n",
        "\n",
        "## Norms\n",
        "\n",
        "-   Common measure of \\`\\`size’’ is the Euclidean norm, or $L^2$ norm\n",
        "    for $x \\in \\mathbb{R}^2$\n",
        "-   Complexity is $O(N)$: requires squaring $N$ times then $N$ additions\n",
        "    to sum. Not nested $$\n",
        "    ||x||_2 = \\sqrt{\\sum_{n=1}^N x_n^2}\n",
        "    $$"
      ],
      "id": "0295e48d-45a0-4eaa-a6c6-c0f14a927a60"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7416573867739413\n",
            "3.7416573867739413\n",
            "3.7416573867739413\n",
            "||x||_2^2 = 14.0 = 14 = 14"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3]) # Calculating different ways (in order of preference)\n",
        "print(np.sqrt(sum(xval**2 for xval in x))) # manual with comprehensions\n",
        "print(np.sqrt(np.sum(np.square(x)))) # broadcasts\n",
        "print(norm(x)) # built-in to numpy norm(x, ord=2) alternatively\n",
        "print(f\"||x||_2^2 = {norm(x)**2} = {x.T @ x} = {np.dot(x, x)}\")"
      ],
      "id": "c209be4f-2b75-49aa-8b7a-bb6fba3e97ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving Systems of Equations\n",
        "\n",
        "-   Solving $A x = b$ for $x$ is equivalent $A^{-1} A x = A^{-1} b$\n",
        "-   Then since $A^{-1}A = I$, and $I x = x$, we have $x = A^{-1} b$\n",
        "-   Careful since matrix algebra is not commutative!"
      ],
      "id": "31470803-95d3-4e70-837d-936fc432a0f3"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([-1.,  1.])"
            ]
          }
        }
      ],
      "source": [
        "A = np.array([[0, 2], [3, 4]]) # or ((0, 2), (3, 4))\n",
        "b = np.array([2,1])  # Column vector\n",
        "x = solve(A, b)  # Solve Ax = b for x\n",
        "x"
      ],
      "id": "fe0544ff-dbd3-4eab-87ce-899575d43bf4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using the Inverse Directly\n",
        "\n",
        "-   Can replace the `solve` with a calculation of an inverse\n",
        "-   But it can be slower or less accurate than solving the system\n",
        "    directly"
      ],
      "id": "4e4079a9-53ea-4551-85ed-581467f00141"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([-1.,  1.])"
            ]
          }
        }
      ],
      "source": [
        "A_inv = inv(A)\n",
        "A_inv @ b # i.e, A^{-1} * b"
      ],
      "id": "76236b0b-0988-45fc-8b8a-3d5c971a6178"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Combinations\n",
        "\n",
        "We can think of solving a system as finding the linear combination of\n",
        "columns of $A$ that equal $b$"
      ],
      "id": "8f0709de-ea9d-48d8-b41a-bb6a44efaeb9"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b = [2 1], b_star = [2. 1.]"
          ]
        }
      ],
      "source": [
        "b_star = x[0] * A[:, 0] + x[1] * A[:, 1] # using x solution\n",
        "print(f\"b = {b}, b_star = {b_star}\")"
      ],
      "id": "f9b77d20-c948-4baf-9de8-74de83e57cb6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Column Space and Rank\n",
        "\n",
        "-   The column space of a matrix represents all possible linear\n",
        "    combinations of its columns.\n",
        "-   It forms a basis for the space of solutions when solving systems of\n",
        "    linear equations represented by the matrix\n",
        "-   The rank of a matrix is the dimension of its column space"
      ],
      "id": "7c19c9ff-c609-48e8-8f64-8c392d5c3fe6"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "2"
            ]
          }
        }
      ],
      "source": [
        "A = np.array([[0, 2], [3, 4]])\n",
        "matrix_rank(A)"
      ],
      "id": "476312cb-7de1-4b08-ac76-0e882b0f811b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hence, can solve $A x = b$ for any $b \\in \\mathbb{R}^2$ since the column\n",
        "space is the entire space $\\mathbb{R}^2$\n",
        "\n",
        "## Singular Matrices\n",
        "\n",
        "On the other hand, note"
      ],
      "id": "7a081e81-52da-4bd7-aca1-1b5822517600"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "1"
            ]
          }
        }
      ],
      "source": [
        "A = np.array([[1, 2],\n",
        "              [2, 4]])\n",
        "matrix_rank(A)"
      ],
      "id": "f725f10d-ba77-48ef-97d5-7253b76ae540"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we can only solve $A x = b$ for\n",
        "$b \\propto \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\propto \\begin{bmatrix} 2 \\\\ 4 \\end{bmatrix}$\n",
        "\n",
        "## Checking Singularity"
      ],
      "id": "16d67a40-6f5b-4e5e-b440-bc2c74257fbe"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "Matrix is singular (non-invertible)."
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 4]])\n",
        "# An (expensive) way to check if A is singular is if det(A) = 0\n",
        "print(det(A) == 0.0)\n",
        "print(matrix_rank(A) != A.shape[0]) # or check rank\n",
        "# Check before inverting or use exceptions\n",
        "try:\n",
        "    inv(A)\n",
        "    print(\"Matrix is not singular (invertible).\")\n",
        "except np.linalg.LinAlgError:\n",
        "    print(\"Matrix is singular (non-invertible).\")"
      ],
      "id": "1bcfde65-b40c-46ea-95f7-c353fd586875"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determinant is Not Scale Invariant\n",
        "\n",
        "-   Reminder: numerical precision in calculations makes it hard to\n",
        "    compare to zero\n",
        "-   The determinate is useful but depends on the scale of the matrix\n",
        "-   A more robust alternative is the condition number (more next\n",
        "    lecture)"
      ],
      "id": "376c9502-2508-4be5-8920-1a8e57a36d75"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "det(A)=-1e-08, det(K*A)=-100\n",
            "cond(A)=1e+09, cond(K*A)=1e+09,\n",
            "det(inv(A))=-1e+08, cond(inv(A))=1e+09"
          ]
        }
      ],
      "source": [
        "eps, K = 1e-8, 100000\n",
        "A = np.array([[1, 2], [1 + eps, 2 + eps]])\n",
        "print(f\"det(A)={det(A):.5g}, det(K*A)={det(K*A):.5g}\")\n",
        "print(f\"cond(A)={cond(A):.5g}, cond(K*A)={cond(A):.5g},\")\n",
        "print(f\"det(inv(A))={det(inv(A)):.5g}, cond(inv(A))={cond(inv(A)):.5g}\")"
      ],
      "id": "83557271-ff8a-4e63-923d-ae1462f9aa97"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solving Linear Systems of Equations\n",
        "\n",
        "## Solving Systems with Multiple RHS\n",
        "\n",
        "-   Inverse is nice because you can reuse the $A^{-1}$ to solve\n",
        "    $A x = b$ for many $b$\n",
        "-   However, you can do this with `solve` as well\n",
        "-   Or can reuse LR factorizations (discussed next)"
      ],
      "id": "a4e7bc33-7874-474e-8bbc-4b74cf404ddc"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.         -1.33333333]\n",
            " [ 1.          1.5       ]]\n",
            "Checking: A*[-1.  1.] = [2. 1.] = [2 1], column of B"
          ]
        }
      ],
      "source": [
        "A = np.array([[0, 2], [3, 4]])\n",
        "B = np.array([[2,3], [1,2]])  # [2,1] and [3,2] as columns\n",
        "# or: B = np.column_stack([np.array([2, 1]),np.array([3,2])])\n",
        "X = solve(A, B)  # Solve AX = B for X\n",
        "print(X)\n",
        "print(f\"Checking: A*{X[:,0]} = {A@X[:, 0]} = {B[:,0]}, column of B\")"
      ],
      "id": "cdf2039f-d129-416a-a399-79a8e405ed04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LU(P) Decompositions\n",
        "\n",
        "-   We can “factor” any square $A$ into $P A = L U$ for triangular $L$\n",
        "    and $U$. Invertible can have $A = L U$, called the LU decomposition.\n",
        "    “P” is for partial-pivoting\n",
        "-   Singular matrices may not have full-rank $L$ or $U$ matrices"
      ],
      "id": "268d65a2-0d99-4f83-95e4-77fc9071252d"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L*U =\n",
            "[[2. 4.]\n",
            " [1. 2.]]\n",
            "P*A =\n",
            "[[2. 4.]\n",
            " [1. 2.]]"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 4]])\n",
        "P, L, U = lu(A)\n",
        "print(f\"L*U =\\n{L @ U}\")\n",
        "print(f\"P*A =\\n{P @ A}\")"
      ],
      "id": "216f637d-e8e0-4f03-a5a8-ddbced7a577a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## P, U, and L\n",
        "\n",
        "The $P$ matrix is a permutation matrix of “pivots” the others are\n",
        "triangular"
      ],
      "id": "5740973d-6a6a-4d55-b182-4fec8c6698e5"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P =\n",
            "[[0. 1.]\n",
            " [1. 0.]]\n",
            "L =\n",
            "[[1.  0. ]\n",
            " [0.5 1. ]]\n",
            "U =\n",
            "[[2. 4.]\n",
            " [0. 0.]]"
          ]
        }
      ],
      "source": [
        "print(f\"P =\\n{P}\")\n",
        "print(f\"L =\\n{L}\")\n",
        "print(f\"U =\\n{U}\")"
      ],
      "id": "7650a075-ff3a-4c94-a787-9a9592a726c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LU Decompositions and Systems of Equations\n",
        "\n",
        "-   Pivoting is typically implied when talking about “LU”\n",
        "-   Used in the default `solve` algorithm (without more structure)\n",
        "-   Solving systems of equations with triangular matrices: for\n",
        "    $A x = L U x = b$\n",
        "    1.  Define $y = U x$\n",
        "    2.  Solve $L y = b$ for $y$ and $U x = y$ for $x$\n",
        "-   Since both are triangular, process is $O(N^2)$ (but LU itself\n",
        "    $O(N^3)$)\n",
        "-   Could be used to find `inv`\n",
        "    -   $A = L U$ then $A A^{-1} = I = L U A^{-1} = I$\n",
        "    -   Solve for $Y$ in $L Y = I$, then solve $U A^{-1} = Y$\n",
        "-   Tight connection to textbook Gaussian elimination (including\n",
        "    pivoting)\n",
        "\n",
        "## LU for Non-Singular Matrices"
      ],
      "id": "79fe614f-27c4-41aa-9774-1a16f992f61e"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L*U =\n",
            "[[3. 4.]\n",
            " [1. 2.]]\n",
            "P*A =\n",
            "[[3. 4.]\n",
            " [1. 2.]]"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [3, 4]])\n",
        "P, L, U = lu(A)\n",
        "print(f\"L*U =\\n{L @ U}\")\n",
        "print(f\"P*A =\\n{P @ A}\")"
      ],
      "id": "acf5e6b0-6f96-41e1-a867-adb3d1d84f48"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## L, U, P"
      ],
      "id": "9b5d0a04-1dae-42a1-af6a-7e5b94c70af4"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P =\n",
            "[[0. 1.]\n",
            " [1. 0.]]\n",
            "L =\n",
            "[[1.         0.        ]\n",
            " [0.33333333 1.        ]]\n",
            "U =\n",
            "[[3.         4.        ]\n",
            " [0.         0.66666667]]"
          ]
        }
      ],
      "source": [
        "print(f\"P =\\n{P}\")\n",
        "print(f\"L =\\n{L}\")\n",
        "print(f\"U =\\n{U}\")"
      ],
      "id": "04b4f341-055b-41f5-8a81-368ca1ce5ee9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backwards Substitution Example\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "U x &= b\\\\\n",
        "U &\\equiv \\begin{bmatrix}\n",
        "3 & 1 \\\\\n",
        "0 & 2 \\\\\n",
        "\\end{bmatrix}, \\quad b = \\begin{bmatrix}\n",
        "7 \\\\\n",
        "2 \\\\\n",
        "\\end{bmatrix}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Solving bottom row for $x_2$\n",
        "\n",
        "$$\n",
        "2 x_2 = 2,\\quad x_2 = 1\n",
        "$$\n",
        "\n",
        "Move up a row, solving for $x_1$, substituting for $x_2$\n",
        "\n",
        "$$\n",
        "3 x_1 + 1 x_2 = 7,\\quad 3 x_1 + 1 \\times 1 =  7,\\quad x_1 = 2\n",
        "$$\n",
        "\n",
        "Generalizes to many rows. For $L$ it is “forward substitution”\n",
        "\n",
        "## Use Triangular Structure if Possible\n",
        "\n",
        "-   Triangular matrices of size $N$ can be solved with back substitution\n",
        "    in $O(N^2)$\n",
        "-   Is $O(N^2)$ good or bad? Beats, $O(N^3)$ typical of general methods"
      ],
      "id": "730d4a3d-2dbd-4a06-ac76-749feb5d0730"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([2., 1.])"
            ]
          }
        }
      ],
      "source": [
        "U = np.array([[3, 1],\n",
        "              [0, 2]])\n",
        "b = np.array([7,2])\n",
        "solve(U,b) # works, but internally does an LU which is O(N^3)\n",
        "solve_triangular(U, b, lower=False) # fast O(N^2)"
      ],
      "id": "10c69b40-b535-4b0a-96be-6cd63e647f95"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Symmetric Matrix Structure\n",
        "\n",
        "Another common matrix type are symmetric, $A = A^{T}$"
      ],
      "id": "6abb42ce-923b-42c3-b9a5-352290d1cb04"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symmetric A? True"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([-3.,  2.])"
            ]
          }
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 5]]) # also posdef, not singular\n",
        "b = np.array([1,4])\n",
        "print(f\"Symmetric A? {scipy.linalg.issymmetric(A)}\")\n",
        "solve(A, b, assume_a=\"sym\") # could also use \"pos\" since positive definite"
      ],
      "id": "b377904e-03c1-4ada-8774-4da4e28342e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Positive Definite Matrices\n",
        "\n",
        "-   A symmetric matrix $A$ is positive definite if $x^T A x > 0$ for all\n",
        "    $x \\neq 0$\n",
        "-   Useful in many areas, such as covariance matrices. Example"
      ],
      "id": "8dc8c5f7-0785-4988-991e-61b5d9d08ee2"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x^T A x = 5"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 5]])\n",
        "x = np.array([0, 1]) # can't really check for all x\n",
        "print(f\"x^T A x = {x.T @ A @ x}\")"
      ],
      "id": "0e082de1-59e1-417e-930e-3a5d69b9f5b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Example of a symmetric matrix that is not positive definite"
      ],
      "id": "69760696-0989-447d-a5f5-4097f55b3c3d"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x^T A x = 0"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 0]])\n",
        "print(f\"x^T A x = {x.T @ A @ x}\")  # one counterexample is enough"
      ],
      "id": "46ac73c1-932b-4a28-967f-4c51e969bce0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We can check these with eigenvalues\n",
        "\n",
        "## Cholesky Decomposition\n",
        "\n",
        "-   For symmetric positive definite matrices: $L = U^T$’\n",
        "-   Called a Cholesky decomposition: $A = L L^T$ for a lower triangular\n",
        "    matrix $L$"
      ],
      "id": "aafcfe9a-6ea0-4bd5-bb45-27255268282e"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [0. 1.]]\n",
            "L*L^T =\n",
            "[[5. 2.]\n",
            " [2. 1.]]"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 5]])\n",
        "L = cholesky(A)\n",
        "print(L)\n",
        "print(f\"L*L^T =\\n{L @ L.T}\")"
      ],
      "id": "a952aca6-0471-46f8-979f-ae898b6a3068"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving Positive Definite Systems"
      ],
      "id": "446ff8ea-eb0a-4b6c-88a4-48b45f485bcd"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.  2.]\n",
            "[1. 4.]"
          ]
        }
      ],
      "source": [
        "A = np.array([[1, 2], [2, 5]])\n",
        "b = np.array([1,4])\n",
        "print(solve(A, b, assume_a=\"pos\")) # uses cholesky internally\n",
        "\n",
        "L = cholesky(A)\n",
        "y = solve_triangular(L, b, lower=True)\n",
        "x = solve_triangular(L.T, y, lower=False)\n",
        "print(x)"
      ],
      "id": "8b41778b-7db7-4c3d-aefa-b2371bc17bb6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cholesky for Covariance Matrices\n",
        "\n",
        "-   Covariance matrices are positive-definite, semi-definite if\n",
        "    degenerate\n",
        "-   Key property of Gaussian random variables:\n",
        "    -   $X \\sim N(\\mu, \\Sigma)$ for\n",
        "        $\\mu \\in \\mathbb{R}^N, \\Sigma \\in \\mathbb{R}^{N \\times N}$\n",
        "    -   $X = \\mu + A Z$ for $Z \\sim N(0_N, I_N)$ where $A A^T = \\Sigma$\n",
        "-   That is, $A$ is the Cholesky decomposition of the covariance matrix\n",
        "\n",
        "# Eigenvalues and Eigenvectors\n",
        "\n",
        "## Eigenvalues and Eigenvectors\n",
        "\n",
        "-   For a square $A$, an eigenvector $x$ and eigenvalue $\\lambda$\n",
        "    satisfy $$\n",
        "    A x = \\lambda x\n",
        "    $$\n",
        "\n",
        "-   $A\\in\\mathbb{R}^{N\\times N}$ has $N$ eigenvalue/eigenvector pairs,\n",
        "    possible multiplicity of $\\lambda$\n",
        "\n",
        "-   Intuition: $x$ is a direction $A x \\propto x$ and $\\lambda$ says how\n",
        "    much it “stretches”\n",
        "\n",
        "-   Properties:\n",
        "\n",
        "    -   For any eigenvector $x$ and scalar $c$ then $c x \\propto A x$ as\n",
        "        well\n",
        "    -   Symmetric matrices have real eigenvalues and orthogonal\n",
        "        eigenvectors. i.e. $x_1 \\cdot x_2 = 0$ for $x_1 \\neq x_2$\n",
        "        eigenvectors. Complex in general\n",
        "    -   Singular if and only if it has an eigenvalue of zero\n",
        "    -   Positive (semi)definite if and only if all eigenvalues are\n",
        "        strictly (weakly) positive\n",
        "    -   Diagonal matrix has eigenvalues as its diagonal\n",
        "    -   Triangular matrix has eigenvalues as its diagonal\n",
        "\n",
        "## Positive Definite and Eigenvalues\n",
        "\n",
        "You cannot check $x^T A x > 0$ for all $x$. Check if “stretching” is\n",
        "positive"
      ],
      "id": "02112e06-1422-4393-ae84-6c8b0e67613b"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.23606798  4.23606798]\n",
            "pos-def? False\n",
            "pos-semi-def? False"
          ]
        }
      ],
      "source": [
        "A = np.array([[3, 1], [2, 1]])\n",
        "# A_eigs = np.real(eigvals(A)) # symmetric matrices have real eigenvalues\n",
        "A_eigs = eigvalsh(A) # specialized for symmetric/hermitian matrices\n",
        "print(A_eigs)\n",
        "is_positive_definite = np.all(A_eigs > 0)\n",
        "is_positive_semi_definite = np.all(A_eigs >= 0) # or eigvals(A) >= -eps\n",
        "print(f\"pos-def? {is_positive_definite}\")\n",
        "print(f\"pos-semi-def? {is_positive_semi_definite}\")"
      ],
      "id": "6314203a-2059-49cd-873f-ad0d5a70b78d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Positive Semi-Definite Matrices **May** Have a Zero Eigenvalue\n",
        "\n",
        "The simplest positive-semi-definite (but not posdef) matrix is"
      ],
      "id": "508567b7-77ae-4e41-85db-7495f87c442c"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n",
            "pos-def? False\n",
            "pos-semi-def? True"
          ]
        }
      ],
      "source": [
        "A_eigs = eigvalsh(np.array([[1, 0], [0, 0]]))\n",
        "print(A_eigs)\n",
        "is_positive_definite = np.all(A_eigs > 0)\n",
        "is_positive_semi_definite = np.all(A_eigs >= 0) # or eigvals(A) >= -eps\n",
        "print(f\"pos-def? {is_positive_definite}\")\n",
        "print(f\"pos-semi-def? {is_positive_semi_definite}\")"
      ],
      "id": "a1107427-8057-41be-85a1-9bece39a3246"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eigenvalue Decomposition\n",
        "\n",
        "-   For square, symmetric, non-singular matrix $A$ factor into\n",
        "\n",
        "$$\n",
        "A = Q \\Lambda Q^{-1}\n",
        "$$\n",
        "\n",
        "-   $Q$ is a matrix of eigenvectors, $\\Lambda$ is a diagonal matrix of\n",
        "    eigenvalues (in order)\n",
        "-   For symmetric matrices, the eigenvectors are orthogonal and\n",
        "    $Q^{-1} Q = Q^T Q = I$, and we can think of them as forming an\n",
        "    orthonormal basis\n",
        "-   Orthogonal matrices can be thought of as rotations without\n",
        "    stretching\n",
        "-   More general matrices all have a Singular Value Decomposition (SVD)\n",
        "-   With symmetric $A$, an interpretation of $A x$ is that we can first\n",
        "    rotate $x$ into the $Q$ basis, then stretch by $\\Lambda$, then\n",
        "    rotate back\n",
        "-   Can be used to find $A^t$ for large $t$ (e.g. for Markov chains)\n",
        "    -   $P^t$, i.e. $P \\cdot P \\cdot \\ldots \\cdot P$ for $t$ times\n",
        "    -   $P = Q \\Lambda Q^{-1}$ then $P^t = Q \\Lambda^t Q^{-1}$ where\n",
        "        $\\Lambda^t$ is just the pointwise power\n",
        "-   Related tools such as SVD can help with dimensionality reduction\n",
        "\n",
        "## Eigenvalue Decomposition of Symmetric Matrix Example"
      ],
      "id": "c51f763c-e36e-4c04-979d-317515148750"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eigenvectors are column-by-column in Q =\n",
            "[[-0.85065081 -0.52573111]\n",
            " [ 0.52573111 -0.85065081]]\n",
            "eigenvalues are in Lambda = [1.38196601+0.j 3.61803399+0.j]\n",
            "Q Lambda Q^T =\n",
            "[[2. 1.]\n",
            " [1. 3.]]"
          ]
        }
      ],
      "source": [
        "A = np.array([[2, 1], [1, 3]])\n",
        "Lambda, Q = eig(A)\n",
        "print(f\"eigenvectors are column-by-column in Q =\\n{Q}\")\n",
        "print(f\"eigenvalues are in Lambda = {Lambda}\")\n",
        "print(f\"Q Lambda Q^T =\\n{Q @ np.diag(np.real(Lambda)) @ Q.T}\")"
      ],
      "id": "b554f491-2784-481b-a017-2e939a7f59eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spectral Radius is Maximum Absolute Eigenvalue\n",
        "\n",
        "-   If any $\\lambda \\in \\Lambda$ are $> 1$ can see this would explode\n",
        "-   Useful for seeing if iteration $x_{t+1} = A x_t$ from a $x_0$\n",
        "    explodes\n",
        "\n",
        "<span class=\"theorem-title\">**Definition 3 (Spectral Radius)\n",
        "**</span>The spectral radius of matrix $A$ is\n",
        "$\\rho(A) = \\max_{\\lambda \\in \\Lambda}|\\lambda|$\n",
        "\n",
        "# Least Squares and the Normal Equations\n",
        "\n",
        "## Least Squares\n",
        "\n",
        "Given a matrix $X \\in \\mathbb{R}^{N \\times M}$ and a vector\n",
        "$y \\in \\mathbb{R}^N$, we want to find $\\beta \\in \\mathbb{R}^M$ such that\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\min_{\\beta} &||y - X \\beta||^2, \\text{ that is,}\\\\\n",
        "\\min_{\\beta} &\\sum_{n=1}^N \\frac{1}{N}(y_n - X_n \\cdot \\beta)^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Where $X_n$ is n’th row. Take FOCS and rearrange to get\n",
        "\n",
        "$$\n",
        "(X^T X) \\beta =  X^T y\n",
        "$$\n",
        "\n",
        "## Solving the Normal Equations\n",
        "\n",
        "-   The $X$ is often referred to as the “design matrix”. $X^T X$ as the\n",
        "    Gram matrix\n",
        "-   Can form $A = X^T X$ and $b = X^T y$ and solve $A \\beta = b$.\n",
        "    -   Or invert $X^T X$ to get $\\beta = (X^T X)^{-1} X^T y$\n",
        "    -   Note that $X^T X$ is symmetric and, if $X$ is full-rank,\n",
        "        positive definite\n",
        "-   In practice, use the `lstsq` function in scipy\n",
        "    -   It uses better algorithms using eigenvectors. More stable (see\n",
        "        next lecture on conditioning)\n",
        "    -   One algorithm uses another factoring, the QR decomposition\n",
        "    -   There, $X = Q R$ for $Q$ orthogonal and $R$ upper triangular.\n",
        "        See [QR\n",
        "        Decomposition](https://python.quantecon.org/qr_decomp.html) for\n",
        "        more\n",
        "-   We are exploring linear algebra in this lecture\n",
        "    -   For applied work use higher-level libraries like `statsmodels`\n",
        "        (integrated well with `pandas` and `seaborn`)\n",
        "    -   See [statsmodels\n",
        "        docs](https://www.statsmodels.org/dev/example_formulas.html) for\n",
        "        R-style notation\n",
        "    -   See [QuanteEcon OLS](https://python.quantecon.org/ols.html) for\n",
        "        later\n",
        "\n",
        "## Example of LLS using Scipy"
      ],
      "id": "7791b0c9-b80b-4b70-8a66-dadb57e00a4e"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta =\n",
            " [ 2.0193851   0.04906271  0.51730453 -0.10376821 -1.0438547 ]\n",
            "beta_hat =\n",
            "[ 2.02166314  0.05038237  0.51144156 -0.09938661 -1.04702165]"
          ]
        }
      ],
      "source": [
        "N, M = 100, 5\n",
        "X = np.random.randn(N, M)\n",
        "beta = np.random.randn(M)\n",
        "y = X @ beta + 0.05 * np.random.randn(N)\n",
        "beta_hat, residuals, rank, s = scipy.linalg.lstsq(X, y)\n",
        "print(f\"beta =\\n {beta}\\nbeta_hat =\\n{beta_hat}\")"
      ],
      "id": "a0da44f4-c7f8-465b-a451-7a093b7aa432"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solving using the Normal Equations\n",
        "\n",
        "Or we can solve it directly. Provide matrix structure (so it can use a\n",
        "Cholesky)"
      ],
      "id": "a1f913fb-0ccd-4e7d-9ca5-91b0d46b02b1"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta =\n",
            " [ 2.0193851   0.04906271  0.51730453 -0.10376821 -1.0438547 ]\n",
            "beta_hat =\n",
            "[ 2.02166314  0.05038237  0.51144156 -0.09938661 -1.04702165]"
          ]
        }
      ],
      "source": [
        "beta_hat = solve(X.T @ X, X.T @ y, assume_a=\"pos\")\n",
        "print(f\"beta =\\n {beta}\\nbeta_hat =\\n{beta_hat}\")"
      ],
      "id": "427278a3-736e-40a9-8eb7-aa2396b4cc15"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collinearity in “Tall” Matrices\n",
        "\n",
        "-   Tall $\\mathbb{R}^{N\\times M}$ “design matrices” have $N > M$ and are\n",
        "    “overdetermined”\n",
        "-   The rank of a matrix is full rank if all columns are linearly\n",
        "    independent\n",
        "-   You can only identify $M$ parameters with $M$ linearly independent\n",
        "    columns"
      ],
      "id": "6d96f66e-d457-4926-adb0-23a267a9979c"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rank(X) = 2, rank(X_col) = 1"
          ]
        }
      ],
      "source": [
        "X = np.array([[1, 2], [2, 5], [3, 7]]) # 3 observations, 2 variables\n",
        "X_col = np.array([[1, 2], [2, 4], [3, 6]]) # all proportional\n",
        "print(f\"rank(X) = {matrix_rank(X)}, rank(X_col) = {matrix_rank(X_col)}\")"
      ],
      "id": "d5d00266-8e22-41a7-83dd-f922ad8e2d41"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collinearity and Estimation\n",
        "\n",
        "-   If $X$ is not full rank, then $X^T X$ is not invertible. For\n",
        "    example:"
      ],
      "id": "e4a3795a-5d7d-4f01-96f8-896e737fb968"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cond(X'*X)=2819.332978639814, cond(X_col'*X_col)=1.1014450683078442e+16"
          ]
        }
      ],
      "source": [
        "print(f\"cond(X'*X)={cond(X.T@X)}, cond(X_col'*X_col)={cond(X_col.T@X_col)}\")"
      ],
      "id": "88141bf2-dbaa-4f3e-a939-a2db39c7f0c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Note that when you start doing operations on matrices, numerical\n",
        "    error creeps in, so you will not get an exact number\n",
        "-   The rule-of-thumb with condition numbers is that if it is\n",
        "    $1\\times 10^k$ then you lose about $k$ digits of precision. So this\n",
        "    effectively means it is singular\n",
        "-   Given the singular matrix, this means a continuum of $\\beta$ will\n",
        "    solve the problem\n",
        "\n",
        "## `lstsq` Solves it? Careful on Interpretation!\n",
        "\n",
        "-   Since $X_{col}^T X_{col}$ is singular, we cannot use\n",
        "    `solve(X.T@X, y)`\n",
        "-   But what about `lstsq` methods?\n",
        "-   As you will see, this gives an answer. Interpretation is hard\n",
        "-   The key is that in the case of non-full rank, you cannot identify\n",
        "    individual parameters\n",
        "    -   Related to “Identification” in econometrics\n",
        "    -   Having low residuals is not enough"
      ],
      "id": "b9f83a4f-98ef-430c-a099-7b9d97dddf51"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta_hat_col = [0.99857143 1.99714286]\n",
            "rank=1, cols=2, norm(X*beta_hat_col-y)=0.0"
          ]
        }
      ],
      "source": [
        "y = np.array([5.0, 10.1, 14.9])\n",
        "beta_hat, residuals, rank, s = scipy.linalg.lstsq(X_col, y)\n",
        "print(f\"beta_hat_col = {beta_hat}\")\n",
        "print(f\"rank={rank}, cols={X.shape[1]}, norm(X*beta_hat_col-y)={norm(residuals)}\")"
      ],
      "id": "9d91d7d8-b384-4561-b344-893d8ad4e7e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fat Design Matrices\n",
        "\n",
        "-   Fat $\\mathbb{R}^{N\\times M}$ “design matrices” have $N < M$ and are\n",
        "    “underdetermined”\n",
        "-   Less common in econometrics, but useful to understand the structure\n",
        "-   A continuum $\\beta\\in\\mathbb{R}^{M - \\text{rank}(X)}$ solve this\n",
        "    problem"
      ],
      "id": "ab208ef4-4b3b-4442-a2cb-8d257bbc9b90"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta_hat = [0.8 0.6 1. ], rank=2, ? residuals = []"
          ]
        }
      ],
      "source": [
        "X = np.array([[1, 2, 3], [0, 5, 7]]) # 2 rows, 3 variables\n",
        "y = np.array([5, 10])\n",
        "beta_hat, residuals, rank, s = scipy.linalg.lstsq(X, y)\n",
        "print(f\"beta_hat = {beta_hat}, rank={rank}, ? residuals = {residuals}\")"
      ],
      "id": "0d361b16-e069-4649-946d-46255ff0c796"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Which Solution?\n",
        "\n",
        "-   Residuals are zero here because there are enough parameters to fit\n",
        "    perfectly (i.e., it is underdetermined)\n",
        "-   Given the multiple solutions, the `lstsq` is giving\n",
        "\n",
        "$$\n",
        "\\min_{\\beta} ||\\beta||_2^2 \\text{ s.t. } X \\beta = y\n",
        "$$\n",
        "\n",
        "-   i.e., the “smallest” coefficients which interpolate the data exactly\n",
        "-   Which trivially fulfills the OLS objective:\n",
        "    $\\min_{\\beta} ||y - X \\beta||_2^2$\n",
        "-   Useful and common in ML, but be **very** careful when interpreting\n",
        "    for economics\n",
        "    -   Tight connections to Bayesian versions of statistical tests\n",
        "    -   But until you understand econometrics and “identification” well,\n",
        "        **stick to full-rank matrices**\n",
        "    -   **Advanced topics:** search for “Regularization”, “Ridgeless\n",
        "        Regression” and “Benign Overfitting in Linear Regression.”"
      ],
      "id": "8a356401-dd1b-4d24-9e93-ec766ff32285"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  }
}